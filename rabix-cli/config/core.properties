backend.execution.directory=.
backend.embedded.types=LOCAL

executor.calculate_file_checksum=true
executor.checksum_algorithm=SHA1

# executor.permission.uid=1000
# executor.permission.gid=1000
executor.set_permissions=true

engine.delete_intermediary_files=false
engine.treat_inputs_as_intermediary=false
engine.set_resources=true

# Supported IN_MEMORY, EVENT_SOURCING and POSTGRES. DB parameters can be set in store.properties
engine.store=IN_MEMORY
gc.enabled=false

executor.resource_fitter_enabled=true

cache.enabled=true
cache.directory=rabix-cache

docker.enabled=true
docker.remove_containers=true
docker.host=unix:///var/run/docker.sock
docker.username=username
docker.password=password

docker.override.auth.enabled=false

#use a different docker client/implementation (eg udocker):
#executor.override.command=/usr/local/bin/docker run {{#volumes}}-v {{location}}:{{path}} {{/volumes}} -w {{workingDir}} {{#env}}-e "{{key}}={{value}}" {{/env}} {{image}} /bin/sh -c "{{#escape}}{{command}}{{/escape}}"

#use singularity to run docker executors:
#executor.override.command=echo \"Bootstrap: docker\nFrom: {{image}}\n\n%runscript\n\n  {{#escape}}{{command}}{{/escape}}\n\n%environment\n {{#env}}\n export  {{key}}={{#escape}}{{value}}{{/escape}};{{/env}}\" > /tmp/script-{{jobId}} && sudo singularity build ./container-{{jobId}} /tmp/script-{{jobId}} && singularity run {{#volumes}}--bind {{path}}:{{location}}  {{/volumes}} --pwd {{workingDir}}  ./container-{{jobId}}

#rabix.tes.client-scheme=http
#rabix.tes.client-host=localhost
#rabix.tes.client-port=8000

#Url to the storage folder, supports file:/ gs:// and s3:// urls
#if gs is used, authentication is taken from the environment
#for s3 the following keys should be added to a config file: s3fs_access_key, s3fs_secret_key

#rabix.tes.storage.base=gs://bucket/folder